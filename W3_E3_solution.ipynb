{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkZhBVg3mSEgvhWCUUoohq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arbinydv/Machine-Learning/blob/main/W3_E3_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9xzHs1JWrE1",
        "outputId": "84891e20-1cc5-41f0-ee5a-7ca06c166a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T1 (Interleaved): True\n",
            "T2 (Shared Memory): False\n",
            "T3 (Sequential Shared): False\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Arbind Kumar Yadav (1690891)\n",
        "Week 3 - Exercise 3 (GPU interleaved and sequential Reduction operations with shared memory)\n",
        "\n",
        "In this exercise, we are implementing and then comparing different parallel reduction methods usin Cupy and it's associated libraries.\n",
        "\"\"\"\n",
        "\n",
        "# Import required libraries\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Global values for vector, thread_per_block (tpb), and blocks_per_grid(bpg)\n",
        "vector_size = 128\n",
        "tpb = 32\n",
        "bpg = math.ceil(vector_size / tpb)\n",
        "\n",
        "def generate_rand_input():\n",
        "    return cp.random.randn(vector_size, dtype=cp.float64)\n",
        "\n",
        "# Task 1: Interleaved Reduction Kernel\n",
        "interleaved_kernel = cp.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void interleaved_reduction(double* xs, int stride) {\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (index % (2 * stride) == 0) {\n",
        "        xs[index] += xs[index + stride];\n",
        "    }\n",
        "}''', 'interleaved_reduction')\n",
        "\n",
        "def interleaved_reduction(vec):\n",
        "    \"\"\"Perform interleaved reduction on GPU.\"\"\"\n",
        "    for i in range(int(math.log2(vector_size))):\n",
        "        stride = 2**i\n",
        "        interleaved_kernel((bpg,), (tpb,), (vec, np.int32(stride)))\n",
        "    return vec[0]\n",
        "\n",
        "\n",
        "# Task 2: Interleaved Reduction with Shared Memory\n",
        "shared_kernel = cp.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void interleaved_shared(double* xs, int size) {\n",
        "    __shared__ double shared_data[220];\n",
        "    int tid = threadIdx.x;\n",
        "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (gid < size)\n",
        "        shared_data[tid] = xs[gid];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2) {\n",
        "        if (tid % (2 * stride) == 0)\n",
        "            shared_data[tid] += shared_data[tid + stride];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0)\n",
        "        xs[blockIdx.x] = shared_data[0];\n",
        "}''', 'interleaved_shared')\n",
        "\n",
        "\"\"\"interleaved reduction with a shared memory.\"\"\"\n",
        "\n",
        "def interleaved_shared_reduction(vec):\n",
        "    shared_kernel((bpg,), (tpb,), (vec, np.int32(vector_size)))\n",
        "    return vec[0]\n",
        "\n",
        "# Task 3: Sequential Reduction with Shared Memory\n",
        "sequential_kernel = cp.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void sequential_shared(double* xs, int size) {\n",
        "    __shared__ double shared_data[220];\n",
        "    int tid = threadIdx.x;\n",
        "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (gid < size)\n",
        "        shared_data[tid] = xs[gid];\n",
        "    else\n",
        "        shared_data[tid] = 0.0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2) {\n",
        "        if (tid % (2 * stride) == 0)\n",
        "            shared_data[tid] += shared_data[tid + stride];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0)\n",
        "        xs[blockIdx.x] = shared_data[0];\n",
        "}''', 'sequential_shared')\n",
        "\n",
        "\"\"\" sequential reduction using shared memory.\"\"\"\n",
        "def sequential_shared_reduction(vec):\n",
        "    sequential_kernel((bpg,), (tpb,), (vec, np.int32(vector_size)))\n",
        "    return vec[0]\n",
        "\n",
        "\n",
        "# Generates random input vector\n",
        "input_vector = generate_rand_input()\n",
        "\n",
        "gpu_interleaved = interleaved_reduction(input_vector.copy())\n",
        "gpu_shared = interleaved_shared_reduction(input_vector.copy())\n",
        "gpu_sequential = sequential_shared_reduction(input_vector.copy())\n",
        "\n",
        "cpu_sum = cp.sum(input_vector)\n",
        "\n",
        "# Checks the results\n",
        "print(\"T1 (Interleaved):\", np.allclose(gpu_interleaved, cpu_sum, atol=1e-6))\n",
        "print(\"T2 (Shared Memory):\", np.allclose(gpu_shared, cpu_sum, atol=1e-6))\n",
        "print(\"T3 (Sequential Shared):\", np.allclose(gpu_sequential, cpu_sum, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEn_RVewWy5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}